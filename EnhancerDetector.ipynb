{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4258ebc2-4f8b-42b2-a6d6-2aa21bf313e7",
   "metadata": {},
   "source": [
    "## The purpose of this notebook is to be the final version of EnhancerDetector for publication\n",
    "\n",
    "### This notebook will take an input fasta file of 400 base pair length and output their probability of being a enhancer\n",
    "### If using fly then the max length can be 500 base pair\n",
    "### Optional, output will also have a Class Activation map of the sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0f28ba-d004-437a-919a-df50d5eebdfb",
   "metadata": {},
   "source": [
    "### @author: Luis Solis, Bioinformatics Toolsmith Laboratory, Texas A&M University-Kingsville\n",
    "### @author: Dr. Hani Z. Girgis, Bioinformatics Toolsmith Laboratory, Texas A&M University-Kingsville\n",
    "\n",
    "#### Date Created: 05-27-2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471d0b34-20f7-415b-8b2b-1a6a10df0419",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "\n",
    "from Nets import CustomConvLayer\n",
    "from Metrics import weighted_f1_score, specificity\n",
    "from OneNucleotideIndexer import OneNucleotideIndexer\n",
    "\n",
    "from Bio import SeqIO\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84744375-8076-464c-a0a9-dac4c231b6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_cam_pdf = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284b8201-824b-48ef-b095-a919f8f8748e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Input will include all sequences that will be tested to see if they are an enhancer or not, this must be in fasta format\n",
    "Output will include the sequence id and their probability of being an enhancer.\n",
    "'''\n",
    "\n",
    "similar_sequences_file = f'Test_Input/input_human.fasta'\n",
    "\n",
    "model_folder = 'Models/'\n",
    "network = f'{model_folder}/Human/Single_Classifier_64_3_20.keras'\n",
    "indexer_dir      = f'{model_folder}/Human/indexer.pkl'\n",
    "\n",
    "output_dir             = f'Output'\n",
    "\n",
    "max_len = 400\n",
    "\n",
    "use_fly = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0641eadd-3e2c-4a57-b52d-9c591e7ca893",
   "metadata": {},
   "source": [
    "### Fly uses a ensemble of three networks, if needed then we load all networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a80fc1-0462-45ef-a2e6-9b7a885e4ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_fly:\n",
    "    max_len = 500\n",
    "    \n",
    "    fly_network1         = f'{model_folder}/Fly/Single_Classifier_40_3_20.keras'\n",
    "    fly_network2         = f'{model_folder}/Fly/Single_Classifier_32_3_20.keras'\n",
    "    fly_network_finetune = f'{model_folder}/Fly/FineTune_Classifier_64_3_20_With_No_Convolution_0.h5'\n",
    "    \n",
    "    human_indexer_dir = f'{model_folder}/Fly/indexer_human.pkl'\n",
    "    fly_indexer_dir   = f'{model_folder}/Fly/indexer_fly.pkl'\n",
    "    \n",
    "    fly_model1 = load_model(fly_network1, custom_objects={'CustomConvLayer': CustomConvLayer, 'specificity': specificity, 'weighted_f1_score': weighted_f1_score})\n",
    "    fly_model2 = load_model(fly_network2, custom_objects={'CustomConvLayer': CustomConvLayer, 'specificity': specificity, 'weighted_f1_score': weighted_f1_score})\n",
    "    fly_model_finetune = load_model(fly_network_finetune, custom_objects={'CustomConvLayer': CustomConvLayer, 'specificity': specificity, 'weighted_f1_score': weighted_f1_score})\n",
    "\n",
    "    with open(human_indexer_dir, 'rb') as f:\n",
    "        human_indexer = pickle.load(f)\n",
    "    human_indexer = OneNucleotideIndexer(max_len, human_indexer)\n",
    "    with open(fly_indexer_dir, 'rb') as f:\n",
    "        fly_indexer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cd42c1-b2ef-4dc3-bd21-87ca99e752b7",
   "metadata": {},
   "source": [
    "### Load model used for EnhancerDetector\n",
    "### Load indexer used for encoding the sequences to numerical format the model understands "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2409336f-90dc-4c0d-9bc0-0dea827b4137",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not use_fly:\n",
    "    model = load_model(network, custom_objects={'CustomConvLayer': CustomConvLayer, 'specificity': specificity, 'weighted_f1_score': weighted_f1_score})\n",
    "    \n",
    "    with open(indexer, 'rb') as f:\n",
    "        indexer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03662493-ea8a-4175-a98c-c57fd9494f50",
   "metadata": {},
   "source": [
    "### Parse input files and grab their names for output and CAM\n",
    "### Encode the input sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66f983c-f042-40a7-8268-886cc542b5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_seq_list = list(SeqIO.parse(similar_sequences_file, \"fasta\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c55fc8c-073c-4376-91d2-dbc52b233e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_name_list = []\n",
    "\n",
    "for seq in similar_seq_list:\n",
    "    similar_name_list.append(seq.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a55817c-e2fa-4d34-9faf-c46fc5810320",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not use_fly:\n",
    "    matrix  = indexer.encode_list(similar_seq_list)\n",
    "else:\n",
    "    matrix_fly   = fly_indexer.encode_list(similar_seq_list)\n",
    "    matrix_human = human_indexer.encode_list(similar_seq_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902b43cd-a901-43de-b3d3-d33adb62db34",
   "metadata": {},
   "source": [
    "### Create a zero tensor with shape of input for the model\n",
    "### Fill in the tensor with data from input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d820189c-b49b-4612-b258-a6400011f923",
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_fly:\n",
    "    batch_size   = matrix_fly.shape[0]\n",
    "    row_size     = 1\n",
    "    column_size  = max_len\n",
    "    channel_size = 1\n",
    "    \n",
    "    tensor  = np.zeros((batch_size, row_size, column_size, channel_size), dtype=np.int8)\n",
    "    tensor_fly  = np.zeros((batch_size, row_size, column_size, channel_size), dtype=np.int8)\n",
    "else:\n",
    "    batch_size   = matrix.shape[0]\n",
    "    row_size     = 1\n",
    "    column_size  = max_len\n",
    "    channel_size = 1\n",
    "    \n",
    "    tensor  = np.zeros((batch_size, row_size, column_size, channel_size), dtype=np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21474c01-25f8-4bdb-8df5-166a5ec3d611",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb3c419-2e80-4101-90b1-1564aca823f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not use_fly: \n",
    "    for i in range(batch_size):\n",
    "        tensor[i, 0, :, 0] = matrix[i]\n",
    "else:\n",
    "    for i in range(batch_size):\n",
    "        tensor_fly[i, 0, :, 0] = matrix_fly[i]\n",
    "        tensor[i, 0, :, 0] = matrix_human[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f356ee-2719-4124-bdd7-5b91bda9d507",
   "metadata": {},
   "source": [
    "### Predict the tensor and write results to output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48544006-3b7e-4cf6-b21d-87ec710ba2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not use_fly:\n",
    "    output_prediction = model.predict(tensor)\n",
    "else:\n",
    "    pred1 = fly_model1.predict(tensor_fly)\n",
    "    pred2 = fly_model2.predict(tensor_fly)\n",
    "    pred3 = fly_model_finetune.predict(tensor)\n",
    "\n",
    "    output_prediction = np.mean([pred1, pred2, pred3], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeaa3043-62ef-495c-9e28-afa965c08557",
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_output = [f\"{value[0]:.2f}\" for value in output_prediction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d8df74-09bf-43a3-b7ca-a882da3642d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{output_dir}/Model_Output.txt', 'w') as file:\n",
    "    for name, percentage in zip(similar_name_list, formatted_output):\n",
    "        file.write(f\"{name} {percentage}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31699949-8d58-4070-b970-f8a95b49ef78",
   "metadata": {},
   "source": [
    "### Below is code for making the CAM model\n",
    "### Cam model was based on code from Deep Learning with Python by Francois Chollet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23405fc7-afaa-46f3-8a1d-7b23a5b32410",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not use_fly:\n",
    "    input_tensor = model.input\n",
    "    \n",
    "    last_conv_layer = model.get_layer('custom_conv_layer_3')  \n",
    "    \n",
    "    cam_model = Model(inputs=input_tensor, outputs=last_conv_layer.output)\n",
    "else:\n",
    "    input_tensor = fly_model1.input\n",
    "    \n",
    "    last_conv_layer = fly_model1.get_layer('custom_conv_layer_3')  \n",
    "    \n",
    "    cam_model = Model(inputs=input_tensor, outputs=last_conv_layer.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef25830-1b43-4b7f-8a3a-7a4b0261463c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not use_fly:\n",
    "    first_dense_layer = model.get_layer('fc_layer_1')\n",
    "    \n",
    "    class_model = Model(inputs=first_dense_layer.input, outputs=model.output)\n",
    "else:\n",
    "    first_dense_layer = fly_model1.get_layer('fc_layer_1')\n",
    "    \n",
    "    class_model = Model(inputs=first_dense_layer.input, outputs=fly_model1.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9e5299-a547-4c24-b41b-c85c6a1189a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_CAM_map(heatmap_interpolated_list, output_dir, name_list, save_pdf):\n",
    "    \"\"\"\n",
    "    Calculates a Class Activation Map (CAM) for a single sequence input.\n",
    "\n",
    "    Inputs:\n",
    "    - x_batch_sample (numpy array): A single input tensor of shape (1, 1, 400, 1)\n",
    "    \n",
    "    Returns:\n",
    "    - heatmap (numpy array): A 1D array representing the importance of each region\n",
    "      in the sequence, normalized between 0 and 1.\n",
    "    \"\"\"\n",
    "    \n",
    "    num_sequences = len(heatmap_interpolated_list)  # Get the actual number of heatmaps\n",
    "    if num_sequences == 0:\n",
    "        print(\"No heatmaps to plot.\")\n",
    "        return\n",
    "    \n",
    "    # Create subplots based on the number of sequences\n",
    "    fig, axs = plt.subplots(num_sequences, 1, figsize=(8.5, 2 * num_sequences))  # Dynamic figure height\n",
    "    if num_sequences == 1:\n",
    "        axs = [axs]  # Make it a list for consistency in the loop\n",
    "    \n",
    "    for i, heatmap_interpolated in enumerate(heatmap_interpolated_list):\n",
    "        # Reshape the heatmap for visualization\n",
    "        image = axs[i].matshow(heatmap_interpolated.reshape(1, -1), cmap='jet', aspect='auto', vmin=0, vmax=1)\n",
    "        \n",
    "        # Customize the plot appearance\n",
    "        axs[i].set_yticks([])\n",
    "        axs[i].xaxis.set_ticks_position('bottom') \n",
    "        axs[i].set_xlim(-0.5, len(heatmap_interpolated))\n",
    "        \n",
    "        # Add title dynamically (use name if available)\n",
    "        title = f'Seq: {name_list}'\n",
    "        axs[i].set_title(title, fontsize=10)\n",
    "        \n",
    "        # Add x-axis label to each plot\n",
    "        axs[i].set_xlabel('Nucleotide position')\n",
    "        \n",
    "        # Hide x-ticks for all except the last plot\n",
    "        if i != num_sequences - 1:\n",
    "            axs[i].set_xticks([])\n",
    "        \n",
    "        # Hide box around the heatmap\n",
    "        for spine in axs[i].spines.values():\n",
    "            spine.set_visible(False)\n",
    "    \n",
    "    # Add a single color bar if there are multiple plots\n",
    "    fig.colorbar(image, ax=axs, orientation='vertical', fraction=0.025, pad=0.02)\n",
    "    \n",
    "    # Adjust layout\n",
    "    #plt.tight_layout()\n",
    "    \n",
    "    # Save as PDF if specified\n",
    "    if save_pdf:\n",
    "        plt.savefig(f'{output_dir}.pdf') \n",
    "\n",
    "    # Show the plot\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820c93b5-89f4-4ba0-8e38-95342496960f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cam(x_batch_sample):\n",
    "    \"\"\"\n",
    "    Plots one or more CAM heatmaps for enhancer sequences.\n",
    "\n",
    "    Inputs:\n",
    "    - heatmap_interpolated_list (list): List of 1D numpy arrays of equal length,\n",
    "      typically interpolated to 400 positions.\n",
    "    - output_dir (str): Directory where PDF heatmaps will be saved.\n",
    "    - name_list (list): List of sequence names for labeling each heatmap.\n",
    "    - save_pdf (bool): If True, saves a PDF file per input set.\n",
    "    \"\"\"\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        # Pass input through the cam model and get the output from the last conv layer\n",
    "        cam_output = cam_model(x_batch_sample, training=False)  # Shape: (1, 1, 22, 512)\n",
    "        \n",
    "        # Flatten the cam output to match the input shape expected by the class model\n",
    "        cam_output_flattened = tf.reshape(cam_output, (1, -1))\n",
    "        \n",
    "        # Watch the cam_output tensor for gradient calculation\n",
    "        tape.watch(cam_output)\n",
    "        \n",
    "        # Pass the flattened output through the classification model\n",
    "        preds = class_model(cam_output_flattened, training=False)\n",
    "        \n",
    "        # Choose the target prediction (for positive/negative class)\n",
    "        target_class_pred = preds[0]  # Assuming binary classification, adjust as needed\n",
    "    \n",
    "    # Calculate gradients with respect to cam_output\n",
    "    grads = tape.gradient(target_class_pred, cam_output)  # Shape: (1, 1, 22, 512)\n",
    "\n",
    "    # Pool the gradients across the spatial dimensions (1, 22) and reduce to get channel-wise weights\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(1, 2))  # Shape: (1, 512)\n",
    "\n",
    "    # Multiply each channel by its corresponding gradient weight\n",
    "    cam_output = cam_output[0]  # Remove batch dimension (22, 512)\n",
    "    heatmap = cam_output * pooled_grads[0]  # Shape: (22, 512)\n",
    "\n",
    "    # Aggregate across channels to get the heatmap\n",
    "    heatmap = tf.reduce_mean(heatmap, axis=-1)  # Shape: (22,)\n",
    "\n",
    "    # Apply ReLU to ensure only positive contributions are kept\n",
    "    heatmap = tf.nn.relu(heatmap)\n",
    "\n",
    "    # Normalize heatmap to range [0, 1] for better visualization\n",
    "    heatmap = heatmap / tf.reduce_max(heatmap)\n",
    "    \n",
    "    #print(\"Heatmap:\", heatmap.numpy())\n",
    "    \n",
    "    return heatmap.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b60759a-b914-4efb-9280-b572e83789af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sequence(idx):\n",
    "    \"\"\"\n",
    "    Retrieves the name of a sequence from the preloaded name list.\n",
    "\n",
    "    Inputs:\n",
    "    - idx (int): Index of the sequence in the input FASTA list.\n",
    "\n",
    "    Returns:\n",
    "    - seq_name (str): Identifier of the sequence for labeling outputs.\n",
    "    \"\"\"\n",
    "    seq_name = similar_name_list[idx]\n",
    "\n",
    "    \n",
    "    return seq_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8906375-df88-489b-a8bb-4a7173f0cb93",
   "metadata": {},
   "source": [
    "### The CAM only gets generated if output_cam_pdf is True\n",
    "### The code will go through each sequence in input and calculate a cam and plot the heatmap\n",
    "### The heatmap will then get outputed to the output file as a pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e90e8d-dd61-4266-9b7f-a1be5adfdaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "if output_cam_pdf:\n",
    "    for i in range(tensor.shape[0]):\n",
    "        if use_fly:\n",
    "            x_input = tensor_fly[i:i+1]\n",
    "        else:\n",
    "            x_input = tensor[i:i+1]\n",
    "\n",
    "        heatmap = calculate_cam(x_input)\n",
    "\n",
    "        # Interpolate CAM to 400 bp\n",
    "        heatmap = heatmap.flatten()\n",
    "        old_indices = np.linspace(0, heatmap.shape[0] - 1, num=heatmap.shape[0])\n",
    "        new_indices = np.linspace(0, heatmap.shape[0] - 1, num=max_len)\n",
    "        heatmap_interpolated = np.interp(new_indices, old_indices, heatmap)\n",
    "\n",
    "        name = get_sequence(i)\n",
    "        plot_CAM_map([heatmap_interpolated], f'{output_dir}/{name}_CAM', [name], save_pdf=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
